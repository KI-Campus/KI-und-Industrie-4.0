{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sz-rI9X6JUE"
   },
   "source": [
    "## Übung Kognitive Robotik - Anwendungsfall Robotergreifen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg-kcTAf6sbw"
   },
   "source": [
    "### Einleitung\n",
    "\n",
    "Eine Einführung in den behandelten Anwendungsfall und die verwendeten Daten wird im Kurselement \"Anwendungsfall Robotergreifen\" gegeben. Sie können gerne noch einmal zu diesem Kurselement zurückkehren, bevor Sie mit der praktischen Übung beginnen.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 1: Erzeugung synthetischer Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits im Einführungsmodul erläutert wurde, besteht eine große Herausforderung beim Einsatz von \n",
    "Machine Learning darin, dass eine ausreichende Datengrundlage für das Training der ML-Modelle vorhanden sein muss. \n",
    "Da das Aufnehmen und Labeln von realen Daten für viele Anwendungsfälle mit beträchtlichem Aufwand verbunden ist, kommen für das Training von ML-Modellen vermehrt synthetische Daten zum Einsatz. Dies sind Daten, die mithilfe von Simulationen oder speziellen Algorithmen künstlich generiert wurden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 1.1: \n",
    "\n",
    "Für den ersten Teil der Übung soll nun ein recht simpler synthetischer Datensatz erzeugt werden. Zu diesem Zweck sollen synthetische Bilder generiert werden, auf denen jeweils ein einfaches geometrisches Objekt zu sehen ist. Im weiteren Verlauf der Übung soll dann eine Objekterkennung für diesen Datensatz umgesetzt werden. Führen Sie die folgenden Codezellen aus. Welche Informationen über den Datensatz können Sie aus der zweiten Codezelle ziehen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten, InputLayer, MaxPool2D, Input\n",
    "from keras.losses import MeanSquaredError, CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from skimage import transform\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import random_noise\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Synthetische Daten\n",
    "\n",
    "num_imgs = 1000\n",
    "\n",
    "img_size = 224\n",
    "min_object_size = 40\n",
    "max_object_size = 80\n",
    "\n",
    "num_classes = 3\n",
    "class_labels = ['Rechteck', 'Kreis', 'Dreieck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_oVk2qyEBkp"
   },
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_1_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 1.2:\n",
    "\n",
    "Neben den Bilddaten müssen dafür auch die entsprechenden Labels erzeugt werden. Wie im Kurselement \"Objekterkennung mit tiefen neuronalen Netzen\" erläutert wurde, ist dies hier für jedes Bild zum einen die Position des Objekts in Form einer Bounding Box und zum anderen die Klasse des Objekts. Betrachten Sie den folgenden Code und denken Sie zurück an das Kurselement \"Objekterkennung mit tiefen neuronalen Netzen\". In welcher Form werden die Bilder und die Labels hier gespeichert?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array für die erzeugten Bilder\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, 3), dtype=np.uint8)\n",
    "print(\"imgs:\", imgs.shape)\n",
    "\n",
    "# Array für die zugehörigen Bounding Boxen\n",
    "bboxes = np.zeros((num_imgs, 4))\n",
    "print(\"bboxes:\", bboxes.shape)\n",
    "\n",
    "# Array für die zugehörigen Klassen\n",
    "classes = np.zeros((num_imgs, num_classes), dtype=int)\n",
    "print(\"classes:\", classes.shape)\n",
    "\n",
    "min_distance_wall = 5 # minimaler Abstand der Objekte vom Bildrand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_1_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9-FqWYcFzQd"
   },
   "source": [
    "#### Aufgabe 1.3: \n",
    "\n",
    "Betrachten Sie den folgenden Code für die Erzeugung der synthetischen Bilddaten. Wie wird hier ein synthetisches Bild generiert? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array für die erzeugten Bilder\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, 3), dtype=np.uint8)\n",
    "print(\"imgs:\", imgs.shape)\n",
    "\n",
    "# Array für die zugehörigen Bounding Boxen\n",
    "bboxes = np.zeros((num_imgs, 4))\n",
    "print(\"bboxes:\", bboxes.shape)\n",
    "\n",
    "# Array für die zugehörigen Klassen\n",
    "classes = np.zeros((num_imgs, num_classes), dtype=int)\n",
    "print(\"classes:\", classes.shape)\n",
    "\n",
    "min_distance_wall = 5 # minimaler Abstand der Objekte vom Bildrand\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    \n",
    "    img = np.ones((img_size,img_size,3), np.uint8) * 255 # Erzeugung eines weißen Bildes\n",
    "\n",
    "    obj_class = np.random.randint(num_classes) #zufällige Wahl der Objektklasse\n",
    "    \n",
    "    c1, c2, c3 = np.random.randint(0, 150, size=3)\n",
    "    mycolor =  (int(c1), int(c2),int(c3)) # zufällige Farbe \n",
    "    \n",
    "    classes[i_img, obj_class] = 1 # Speichern der Klasse, One-Hot-Encoding\n",
    "    \n",
    "    if obj_class == 0: #Rechteck\n",
    "        w, h = np.random.randint(min_object_size, max_object_size, size=2) # Breite und Höhe\n",
    "        x = np.random.randint(min_distance_wall, img_size - w -min_distance_wall) # x-Position im Bild\n",
    "        y = np.random.randint(min_distance_wall, img_size - h -min_distance_wall) # y-Position im Bild\n",
    "        cv.rectangle(img, (x+0,y+0), (x+w-1,y+h-1), mycolor, -1) # Erzeugung Rechteck im Bild\n",
    "        bbox = [x, y+h, x+w, y] # Bounding Box \n",
    "                        \n",
    "    elif obj_class == 1: # Kreis   \n",
    "        r = 0.5 * np.random.randint(min_object_size, max_object_size) # Radius\n",
    "        x = np.random.randint(r+2, img_size-r-2) # x-Position im Bild\n",
    "        y = np.random.randint(r+2, img_size-r-2) # y-Position im Bild\n",
    "        cv.circle(img,(x,y), int(r), mycolor, -1) # Erzeugung Kreis im Bild\n",
    "        bbox = [x-r, y+r, x+r, y-r] # Bounding Box\n",
    "        \n",
    "    elif obj_class == 2: # Dreieck\n",
    "        w, h = np.random.randint(min_object_size, max_object_size, size=2) # Breite und Höhe\n",
    "        x = np.random.randint(min_distance_wall, img_size - w -min_distance_wall) # x-Position im Bild\n",
    "        y = np.random.randint(min_distance_wall, img_size - h -min_distance_wall) # y-Position im Bild\n",
    "        triangle_cnt = np.array( [(x,y), (x+w,y), (x,y+h)] )\n",
    "        cv.drawContours(img, [triangle_cnt], 0, mycolor, -1) # Erzeugung Dreieck im Bild\n",
    "        bbox = [x, y+h, x+w, y] # Bounding Box\n",
    "        \n",
    "    imgs[i_img] = img\n",
    "    bboxes[i_img] = bbox\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsgAfbaAGArt"
   },
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_1_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 2: Exploration der Daten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkcMs3i-EgOf"
   },
   "source": [
    "#### Aufgabe 2.1: \n",
    "\n",
    "Überprüfen Sie die erzeugten synthetischen Daten stichprobenhaft. Enthält jedes Bild eines der drei geometrischen Objekte? Sind die Labels, d. h. die Bounding Boxen und die Klassen korrekt? Sind alle Objekte vollständig im Bild? Etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Urj51HZ9HHDl"
   },
   "outputs": [],
   "source": [
    "temp_imgs = np.copy(imgs) # Erzeugung einer Kopie der Bilder \n",
    "\n",
    "# Plotten von einigen Beispielbildern\n",
    "def plot_example_imgs(imgs,bboxes,classes):\n",
    "    \n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i_subplot in range(1, 17):\n",
    "        plt.subplot(4, 4, i_subplot)\n",
    "        i = np.random.randint(len(imgs))\n",
    "        \n",
    "        # Bild \n",
    "        plt.imshow(imgs[i], origin='lower')\n",
    "        ax = plt.gca()\n",
    "        \n",
    "        # Bounding Box\n",
    "        x, y = bboxes[i,0], bboxes[i,3]\n",
    "        w, h = (bboxes[i,2] - bboxes[i,0]), (bboxes[i,1] - bboxes[i,3])\n",
    "        box = patches.Rectangle((x, y), w, h, linewidth=3, edgecolor='g', facecolor=\"none\")\n",
    "        ax.add_patch(box)\n",
    "        \n",
    "        # Klasse\n",
    "        class_num = np.argmax(classes[i])\n",
    "        plt.text(imgs.shape[2]-100,imgs.shape[1]+5, class_labels[class_num], color='g')\n",
    "        \n",
    "plot_example_imgs(temp_imgs,bboxes,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_2_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 2.2:\n",
    "\n",
    "Wie sind die Daten auf die Klassen verteilt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = np.sum(classes, axis=0)/np.sum(classes)\n",
    "for i in range(3):\n",
    " print(class_labels[i], class_dist[i]*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_2_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 3: Datenvorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 3.1: \n",
    "\n",
    "Im ersten Schritt der Datenvorverarbeitung werden die Pixelwerte neu skaliert. Was genau wird hier gemacht und warum? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_normalization(imgs):\n",
    "   \n",
    "    h = imgs.shape[1]\n",
    "    b = imgs.shape[2]\n",
    "    \n",
    "    imgs = tf.cast(imgs, tf.float32)\n",
    "    s = tf.constant(255.0,  dtype = tf.float32)\n",
    "    imgs_scaled = tf.math.divide(imgs,s)\n",
    "    \n",
    "    print(\"Vorher:\")\n",
    "    print(tf.reshape(imgs[0],(h,b,3)))\n",
    "    print(\"Nachher:\")\n",
    "    print(tf.reshape(imgs_scaled[0],(h,b,3)))\n",
    "    \n",
    "    return imgs_scaled\n",
    "\n",
    "imgs_scaled = pixel_normalization(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_3_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 3.2\n",
    "\n",
    "Im nächsten Schritt der Datenvorverarbeitung werden auch die Bounding Boxen neu skaliert. Was genau wird hier gemacht und warum?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_normalization(bboxes, imgs):\n",
    "    \n",
    "    print(\"Vorher: min\", np.min(bboxes), \"max\", np.max(bboxes))\n",
    "    \n",
    "    h = imgs.shape[1]\n",
    "    b = imgs.shape[2]\n",
    "    \n",
    "    bboxes[:,0] = bboxes[:,0]/b\n",
    "    bboxes[:,1] = bboxes[:,1]/h\n",
    "    bboxes[:,2] = bboxes[:,2]/b\n",
    "    bboxes[:,3] = bboxes[:,3]/h\n",
    "    \n",
    "    print(\"Nachher: min\", np.min(bboxes), \"max\", np.max(bboxes))\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "bboxes = bbox_normalization(bboxes, imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_3_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-05T23:55:33.242000",
     "start_time": "2016-07-05T23:55:33.179000"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhITQFjtlDLM",
    "outputId": "089a6e90-f20c-4f46-bb2e-56590dcd9804"
   },
   "source": [
    "### Schritt 4: Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moh3TGiXX4Gb"
   },
   "source": [
    "#### Aufgabe 4.1:\n",
    "\n",
    "Als Nächstes muss der erzeugte synthetische Datensatz in Trainingsdaten und Testdaten aufgeteilt werden. Dabei sollen 80 % der Daten als Trainingsdaten und 20 % der Daten als Testdaten verwendet werden. Ergänzen Sie den gegebenen Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-05T23:55:33.989000",
     "start_time": "2016-07-05T23:55:33.981000"
    },
    "id": "cT5Sy9ejlDLM"
   },
   "outputs": [],
   "source": [
    "# Aufteilung der Daten in Trainings- und Testdaten \n",
    "\n",
    "n_train = int(0.8 * num_imgs) # Anzahl der Bilder, die zum Trainingsdatensatz gehören sollen\n",
    "\n",
    "# Trainingsdaten\n",
    "x_train = imgs_scaled[:n_train] # Die ersten n_train Bilder gehören zum Trainingsdatensatz\n",
    "bboxes_train = bboxes[:n_train]\n",
    "class_train = classes[:n_train]\n",
    "\n",
    "#Testdaten\n",
    "x_test =      # Die restlichen Bilder gehören zum Testdatensatz\n",
    "bboxes_test = \n",
    "class_test = \n",
    "\n",
    "print(\"Anzahl Bilder Trainingsdatensatz: \", len(x_train))\n",
    "print(\"Anzahl Bilder Testdatensatz: \", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_4_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 5: Umsetzung Objekterkennung mit einem Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden soll eine Objekterkennung mit einem Convolutional Neural Network (CNN) für die erzeugten synthetischen Daten umgesetzt werden. Auf die Funktionsweise von CNNs wird später im Modul Qualitätsprüfung eingegangen. Hier werden Sie zunächst als Black Box betrachtet. Der Aufbau des verwendeten Netzes wurde im Kurselement \"Objekterkennung mit tiefen neuronalen Netzen\" genauer erläutert und ist zur Erinnerung in der folgenden Grafik noch einmal dargestellt.  \n",
    "\n",
    "<img src=\"img/Netzarchitektur.png\" width=500 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCrirms2X8Ek"
   },
   "source": [
    "#### Aufgabe 5.1: \n",
    "\n",
    "Betrachten Sie die Abbildung der Netzwerkarchitektur und versuchen Sie den gegebenen Code für die Erstellung des Modells nachzuvollziehen. \n",
    "\n",
    "Wie Sie dem Code entnehmen können, werden drei verschiedene Aktivierungsfunktionen für die verschiedenen Schichten des Netzes verwendet. Welche sind das und wie sehen diese Aktivierungsfunktionen aus? Warum macht es Sinn diese für die entsprechenden Schichten des Netzes zu verwenden? \n",
    "\n",
    "Informationen zu verschiedenen Aktivierungsfunktionen und Hinweise zur Lösung der Aufgabe finden Sie u. a. hier: https://www.geeksforgeeks.org/activation-functions-neural-networks/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_AmBcm2uIV5",
    "outputId": "98662c92-64cd-4883-dacb-7f6078df3ba2"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    # Eingabe\n",
    "    inputs = Input(shape=x_train.shape[1:])\n",
    "    \n",
    "    # CNN\n",
    "    x = Convolution2D(filters=32,kernel_size=(3,3), activation=\"relu\")(inputs)\n",
    "    x = MaxPool2D(pool_size=(3,3))(x)\n",
    "    x = Convolution2D(filters=16,kernel_size=(3,3), activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(3,3))(x)\n",
    "    x = Convolution2D(filters=8,kernel_size=(3,3), activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(3,3)) (x)\n",
    "    x = Flatten() (x)\n",
    "\n",
    "    # Lokalisierung (Regressionsproblem)\n",
    "    x_1 = Dense(128, activation=\"relu\")(x)\n",
    "    x_1 = Dropout(0.3)(x_1)\n",
    "    x_1 = Dense(64,  activation=\"relu\")(x_1)\n",
    "    x_1 = Dropout(0.3)(x_1)\n",
    "    output_bb = Dense(4, activation=\"sigmoid\", name='output_bb')(x_1) # Ausgabe Bounding Box\n",
    "\n",
    "    # Klassifizierung (Klassifikationsproblem)\n",
    "    x_2 = Dense(64, activation=\"relu\")(x)\n",
    "    x_2 = Dropout(0.3)(x_2)\n",
    "    x_2 = Dense(32, activation=\"relu\")(x_2)\n",
    "    x_2 = Dropout(0.3)(x_2)\n",
    "    output_class = Dense(3, activation=\"softmax\", name='output_class')(x_2) # Ausgabe Wahrscheinlichkeit Objektklasse\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[output_bb, output_class])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# Speichern der zufällig initialisierten Gewichte des Modells \n",
    "model.save_weights('model_default_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_5_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 5.2:\n",
    "\n",
    "Betrachten Sie den folgenden Code und führen Sie ihn aus, um das erstellte Modell zu trainieren. Das Training des Modells benötigt ca. 10 Minuten. Nutzen Sie diese Zeit, um die folgenden Fragen zu beantworten.\n",
    "\n",
    "a) Wie wird hier der Fehler zwischen den Vorhersagen des Netzes und den gegebenen Labels (Loss) berechnet? \n",
    "\n",
    "b) Welcher Anteil der Trainingsdaten wird für die Validierung verwendet? \n",
    "\n",
    "c) Welche Gewichte werden während des Trainings des Modells gespeichert? \n",
    "\n",
    "Falls das Training zu lange dauert, können Sie auch die Musterlösung laden.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ1m15tmD1wo"
   },
   "outputs": [],
   "source": [
    "lr = 0.001 # Lernrate\n",
    "num_epochs = 40 # Anzahl Epochen\n",
    "batch_size = 64 # Batch size\n",
    "\n",
    "# Gewichtung der Fehler \n",
    "w_1 = 10.0 # Lokalisierung\n",
    "w_2 = 1.0 # Klassifizierung\n",
    "\n",
    "# Laden der zufälligen Startgewichte des Netzes  \n",
    "model.load_weights('model_default_weights.h5')\n",
    "\n",
    "opt = Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(loss={'output_bb' : 'mean_squared_error', 'output_class' : 'categorical_crossentropy'}, \n",
    "              loss_weights=[w_1,w_2],\n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "                            filepath=\"my_model.h5\",\n",
    "                            monitor='val_loss',\n",
    "                            mode='min',\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=False)\n",
    "\n",
    "history = model.fit(\n",
    "                    x_train,\n",
    "                    (bboxes_train, class_train),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe a) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_5_2_a.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe b) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_5_2_b.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5ZZfLNyEBHR",
    "outputId": "58d0135c-c25f-428f-aa73-f0c2999b5013"
   },
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe c) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_5_2_c.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sie können entweder mit dem von Ihnen trainierten Netz weiterarbeiten oder mit der Musterlösung \n",
    "\n",
    "# Von Ihnen trainiertes Netz laden \n",
    "model.load_weights('my_model.h5')\n",
    "\n",
    "# Musterlösung laden \n",
    "#model.load_weights('solution_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OMlJEXvaQ8G"
   },
   "source": [
    "### Schritt 6: Evaluation Objekterkennung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 6.1: \n",
    "\n",
    "Testen Sie das trainierte neuronale Netz auf einigen Beispielbildern aus dem Testdatensatz. \n",
    "\n",
    "a) Ergänzen Sie dazu den folgenden Code. \n",
    "\n",
    "b) Wie gut funktioniert die Lokalisierung und die Klassifikation der Objekte?     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "47eOO_ZPaDJE",
    "outputId": "38239c7f-35fe-4fac-f55a-4bb38a822cdf"
   },
   "outputs": [],
   "source": [
    "# Wähle zufällig 16 Bilder aus dem Testdatensatz und plotte die korrekten und die vom Netz vorhergesagten Bboxes und Klassen\n",
    "def plot_example_imgs_pred(x_test, bboxes_test, class_test, img_size, model):\n",
    "    \n",
    "    # Wähle zufällig 16 Bilder aus dem Testdatensatz\n",
    "    myPlotSample = np.array(x_test)\n",
    "    rnd_sample = np.random.randint(len(myPlotSample), size=16)\n",
    "    images_show = myPlotSample[rnd_sample]\n",
    "    \n",
    "    # korrekte Bounding Boxen und Klassen\n",
    "    true_bboxes = bboxes_test[rnd_sample]*img_size\n",
    "    true_class = class_test[rnd_sample]\n",
    "    \n",
    "    # Wende das trainierte neuronale Netz an, um Bounding Boxen und Objektklassen für die Testbilder vorherzusagen   \n",
    "    pred_y = model.predict(images_show)\n",
    "    pred_bboxes = pred_y[0]*img_size\n",
    "    pred_class = pred_y[1]\n",
    "    \n",
    "    # Plotte testbilder\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i in range(16):\n",
    "    \n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(images_show[i], origin='lower')\n",
    "        ax = plt.gca()\n",
    "    \n",
    "        # korrekte Bounding Boxen (grün)\n",
    "        x, y = true_bboxes[i,0], true_bboxes[i,3]\n",
    "        w, h = (true_bboxes[i,2] - true_bboxes[i,0]), (true_bboxes[i,1] - true_bboxes[i,3])\n",
    "        box_true = patches.Rectangle((x, y), w, h, linewidth=3, edgecolor='g', facecolor=\"none\")     \n",
    "        ax.add_patch(box_true)\n",
    "        \n",
    "        # vorhergesagte Bounding Boxen (rot) \n",
    "        # Ergänzen Sie den Code\n",
    "    \n",
    "        # vorhergesagte und korrekte Klasse\n",
    "        predicted_class_num = np.argmax(pred_class[i])\n",
    "        true_class_num = np.argmax(true_class[i])\n",
    "        plt.text(0,x_test.shape[1]+5,class_labels[predicted_class_num], color='r') # vorhergesagte Klasse (grün) \n",
    "        plt.text(x_test.shape[2]-100,x_test.shape[1]+5, class_labels[true_class_num], color='g') # korrekte Klasse (rot)\n",
    "    \n",
    "    return\n",
    "\n",
    "plot_example_imgs_pred(x_test, bboxes_test, class_test, img_size, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe a) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_6_1_a.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe b) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_6_1_b.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 6.2:\n",
    "\n",
    "In der vorherigen Aufgabe wurde die Performance des trainierten neuronalen Netzes qualitativ anhand einiger Beispielbilder beurteilt. In dieser und der folgenden Aufgabe soll die Performance nun anhand gängiger Metriken\n",
    "quantitativ beurteilt werden. Zunächst soll dabei die Performance der Lokalisierung anhand der IoU (intersection over union) betrachtet werden. Für eine Erklärung von IoU sei auf das Kurselement \"Methoden zur Evaluation der Objekterkennung\" verwiesen.   \n",
    "\n",
    "Standardmäßig wird eine Bounding Box als korrekt vorhergesagt betrachtet, wenn IoU >= 0.5 ist. Teilweise wird aber auch die Performance für verschiedene Schwellwerte angegeben. Für wie viel Prozent der Testdaten ist IoU >= 0.25, 0.5, 0.75, 0.95. Was sagt dies über die Performance des Netzes bei der Lokalisierung aus?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für die Berechnung IoU\n",
    "def calc_IoU(box_true, box_pred):\n",
    "    # Fläche Überschneidung von vorhergesagter und korrekter Bounding Box\n",
    "    x1 = max(box_true[0],box_pred[0])\n",
    "    y1 = min(box_true[1],box_pred[1])\n",
    "    x2 = min(box_true[2],box_pred[2])\n",
    "    y2 = max(box_true[3],box_pred[3])\n",
    "    intersection_area = max(0, x2 -  x1) * max(0, y1 - y2)\n",
    "    # Fläche korrekte Bounding Box \n",
    "    true_box_area = (box_true[2] - box_true[0]) * (box_true[1] - box_true[3])\n",
    "    # Fläche vorhergesagte Bounding Box\n",
    "    pred_box_area = (box_pred[2] - box_pred[0]) * (box_pred[1] - box_pred[3])\n",
    "    # Berechnung Intersection over Union\n",
    "    IoU = intersection_area / (true_box_area + pred_box_area - intersection_area)\n",
    "    return IoU\n",
    "\n",
    "# Funktion für die Evaluation \n",
    "def eval_bbox_prediction(bbox_true, bbox_pred, threshold):\n",
    "    iou_test = np.zeros(len(bbox_true))\n",
    "    for j in range(len(bbox_true)):\n",
    "        iou_test[j] = calc_IoU(bbox_true[j],bbox_pred[j])\n",
    "    correct = np.sum(iou_test >= threshold)\n",
    "    print(\"Korrekt vorhergesagte Bounding Boxen: \", correct, \"von\", len(bbox_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation der Lokalisierung auf den Testdaten \n",
    "threshold = 0.5 # Schwellwert IoU, ab dem Bounding Box als korrekt vorhergesagt betrachtet wird \n",
    "\n",
    "box_true = bboxes_test\n",
    "box_pred = model.predict(x_test)[0]\n",
    "\n",
    "eval_bbox_prediction(box_true,box_pred,threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_6_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 6.3:\n",
    "\n",
    "Als Nächstes soll die Performance des Netzes bei der Klassifikation mithilfe einer Konfusionsmatrix quantitativ beurteilt werden. Bewerten Sie das Ergebnis.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_class_prediction(true_class,pred_class):\n",
    "    true_class_max = np.argmax(true_class,axis=1)\n",
    "    pred_class_max = np.argmax(pred_class,axis=1)\n",
    "   \n",
    "    N_correct = np.sum(true_class_max == pred_class_max)\n",
    "    print('Korrekt vorhergesagte Klassen: ', N_correct, 'von', len(x_test))\n",
    "    \n",
    "    cm = confusion_matrix(y_true=true_class_max, y_pred=pred_class_max)\n",
    "    cmap = cmap=plt.cm.Reds\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.xticks([0,1,2],class_labels)\n",
    "    plt.yticks([0,1,2],class_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"black\")\n",
    "\n",
    "    plt.ylabel('Korrekte Klasse')\n",
    "    plt.xlabel('Vorhergesagte Klasse')\n",
    "    plt.title('Konfusionsmatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation der Klassifikation\n",
    "eval_class_prediction(class_test, model.predict(x_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_6_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 6.4:\n",
    "\n",
    "Als Nächstes soll getestet werden, wie sich die Performance des Netzes auf leicht veränderten Bildern verhält. Dazu wird künstliches Rauschen auf die Bilder gelegt. Experimentieren Sie mit der Menge an Rauschen und beobachten Sie, wie sich die Performance des Netzes verhält. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_noise = 0.01 # Menge an Rauschen\n",
    "\n",
    "def noisy_image(input_imgs):\n",
    "    noisy_imgs = np.copy(input_imgs)\n",
    "    for i in range(len(input_imgs)):\n",
    "        # Hinzufügen von \"salt and pepper noise\"\n",
    "        noisy_imgs[i] = random_noise(noisy_imgs[i], mode='s&p', clip=True, amount=amount_of_noise)\n",
    "    return noisy_imgs\n",
    "\n",
    "x_test_noisy = noisy_image(x_test)\n",
    "\n",
    "# Plotte Beispielbild mit Rauschen\n",
    "plt.imshow(x_test_noisy[0], origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bbox_prediction(bboxes_test,model.predict(x_test_noisy)[0],threshold=0.5)\n",
    "eval_class_prediction(class_test, model.predict(x_test_noisy)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_6_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 7: Augmentierung der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die schlechte Extrapolationsfähigkeit von neuronalen Netzen wird insbesondere dann zum Problem, wenn der für das Training vorhandene Datensatz eher klein ist und hauptsächlich sehr ähnliche Daten enthält. In diesem Fall setzt man häufig sogenannte Augmentierung (engl. Augmentation) ein, um die Varianz und die Menge der Trainingsdaten zu erhöhen und so die Genauigkeit und die Robustheit des gelernten Machine Learning Modells zu verbessern. Bei der Augmentierung von Bilddaten (Image Augmentation) werden, basierend auf den vorhandenen Bildern, neue zusätzliche Bilder für das Training erzeugt. Dazu werden verschiedene Operationen wie zufällige Rotation, Spiegelung, Hinzufügen von künstlichem Rauschen, Veränderung des Kontrasts, etc. auf die ursprünglichen Bilder angewandt. \n",
    "\n",
    "Beim Einsatz von synthetischen Daten führt die schlechte Extrapolationsfähigkeit von neuronalen Netzen häufig dazu, dass ein Modell, welches auf synthetischen Daten trainiert wurde und auf diesen eine sehr gute Performance erreicht, auf realen Daten eine deutlich schlechtere Performance zeigt. Dies liegt daran, dass sich die synthetischen Daten eigentlich immer in gewisser Weise von den realen Daten unterscheiden. Auch hier kann Augmentierung helfen ein robusteres Machine Learning Modell zu trainieren, welches besser generalisiert und auch in der Realität gute Vorhersagen liefert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 7.1:\n",
    "\n",
    "Wie bereits erläutert, können Bilder auf unterschiedliche Weise augmentiert werden. Im Folgenden sind vier Funktionen für die Augmentierung der synthetischen Bilder definiert. Wie verändern diese Funktionen die ursprünglichen Bilder?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition verschiedener Augmentierungsfunktionen  \n",
    "    \n",
    "def brightness(image):\n",
    "    max_val = 1-np.min(image)-0.4\n",
    "    bright = np.random.random(1)*max_val\n",
    "    im_bright = image + bright\n",
    "    im_bright = np.clip(im_bright, 0.0, 1.0)\n",
    "    return im_bright\n",
    "\n",
    "def darkness(image):\n",
    "    max_val = np.min(image)\n",
    "    dark = np.random.random(1)*max_val\n",
    "    im_dark = image - dark\n",
    "    im_dark = np.clip(im_dark, 0.0, 1.0)\n",
    "    return im_dark\n",
    "\n",
    "def noise(image):\n",
    "    amount = np.random.uniform(0.0,0.05,1)\n",
    "    im_noise = random_noise(image, mode='s&p', clip=True, amount=amount[0])\n",
    "    return im_noise \n",
    "    \n",
    "def blur(image):\n",
    "    rand = np.random.randint(0,5)\n",
    "    im_blur = cv.GaussianBlur(image,(5,5), rand)\n",
    "    return(im_blur)\n",
    "\n",
    "# Testbild augmentieren\n",
    "original_img = x_test[0]\n",
    "augmented_img = brightness(original_img) # brightness kann hier durch die anderen definierten Funktionen ersetzt werden\n",
    "\n",
    "# Visualisierung \n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1, title=\"original\")\n",
    "plt.imshow(original_img, origin=\"lower\")\n",
    "plt.subplot(1, 2, 2, title=\"augmented\")\n",
    "plt.imshow(augmented_img, origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_7_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 7.2:\n",
    "\n",
    "Im nächsten Schritt soll basierend auf dem Trainingsdatensatz ein gleich großer Datensatz mit augmentierten Bildern erzeugt werden. Betrachten Sie den folgenden Code und führen Sie ihn aus. Wie werden die augmentierten Bilder erzeugt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung eines Datensatzes mit augmentierten Bildern\n",
    "\n",
    "def create_augmented_imgs(imgs,bboxes,classes):\n",
    "    \n",
    "    num_augimgs = len(imgs) # Anzahl zu erzeugender augmentierter Bilder\n",
    "\n",
    "    # Platzhalter für augmentierte Bilder, Bounding Boxen und Klassen\n",
    "    aug_imgs = np.ones(shape=imgs.shape)\n",
    "    aug_bboxes = np.ones(shape=(num_augimgs,4))\n",
    "    aug_classes = np.ones(shape=(num_augimgs,3))\n",
    "\n",
    "    temp_train_imgs = np.array(imgs)\n",
    "\n",
    "    for i in range(num_augimgs):\n",
    "        sample = np.random.randint(len(temp_train_imgs)) # zufällige Wahl eines Bildes aus dem Trainingsdatensatz\n",
    "        aug_img = temp_train_imgs[sample]\n",
    "        aug = np.random.random(4) # zufällige Auswahl der Operationen, die auf das Bild angewandt werden\n",
    "        if (aug[0]>0.5):\n",
    "            aug_img = brightness(aug_img) # Aufhellung\n",
    "        if (aug[1]>0.5):\n",
    "            aug_img = darkness(aug_img) # Verdunklung\n",
    "        if (aug[2]>0.5):\n",
    "            aug_img = noise(aug_img) # Rauschen\n",
    "        if (aug[3]>0.5):\n",
    "            aug_img = blur(aug_img) # Unschärfe\n",
    "        aug_imgs[i] = aug_img\n",
    "        aug_bboxes[i] = bboxes[sample]\n",
    "        aug_classes[i] = classes[sample]\n",
    "    return aug_imgs, aug_bboxes, aug_classes\n",
    "\n",
    "# Erzeugung augmentierter Bilddaten \n",
    "aug_imgs, aug_bboxes, aug_classes = create_augmented_imgs(x_train, bboxes_train, class_train)\n",
    "\n",
    "# Plotten einiger Beispielbilder\n",
    "N,h,b,c = aug_imgs.shape\n",
    "size = np.array([b,h,b,h])\n",
    "plot_example_imgs(aug_imgs, aug_bboxes*size, aug_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_7_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 7.3:\n",
    "\n",
    "Nun soll ein neuer Trainingsdatensatz erstellt werden, der sowohl die ursprünglichen Bilder, wie auch die augmentierten Bilder enthält. Ergänzen Sie den folgenden Code.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung eines neuen Trainingsdatensatzes mit den originalen und den augmentierten Bildern  \n",
    "\n",
    "x_train_aug = np.concatenate((x_train,aug_imgs), axis=0)\n",
    "bboxes_train_aug = \n",
    "class_train_aug = \n",
    "\n",
    "# Durchmischung der Bilder\n",
    "x_train_aug, bboxes_train_aug, class_train_aug = shuffle(x_train_aug, bboxes_train_aug, class_train_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_7_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 8: Training des Modells mit dem neuen Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 8.1:\n",
    "\n",
    "Im Folgenden ist der Code aus Aufgabe 5.2 (Training des Modells auf dem ursprünglichen Datensatz) gegeben. Passen Sie den Code entsprechend an und trainieren Sie das Modell auf dem neuen Datensatz.  \n",
    "\n",
    "Das Training des Modells benötigt ca. 10 Minuten. Falls das Training zu lange dauert, können Sie auch die Musterlösung laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 # Lernrate\n",
    "num_epochs = 40 # Anzahl Epochen \n",
    "batch_size = 64 # Batch size\n",
    "\n",
    "# Gewichtung der Fehler \n",
    "w_1 = 10.0 # Lokalisierung\n",
    "w_2 = 1.0 # Klassifizierung\n",
    "\n",
    "# Laden der zufälligen Startgewichte des Netzes  \n",
    "model.load_weights('model_default_weights.h5')\n",
    "\n",
    "opt = Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(loss={'output_bb' : 'mean_squared_error', 'output_class' : 'categorical_crossentropy'}, \n",
    "              loss_weights=[w_1,w_2],\n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "                            filepath=\"my_model_aug.h5\", # diese Zeile wurde bereits geändert, um das alte Modell nicht zu überschreiben\n",
    "                            monitor='val_loss',\n",
    "                            mode='min',\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=False)\n",
    "\n",
    "history = model.fit(\n",
    "                    x_train,\n",
    "                    (bboxes_train, class_train),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_8_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sie können entweder mit dem von Ihnen trainierten Netz weiterarbeiten oder mit der Musterlösung \n",
    "\n",
    "# Von Ihnen trainiertes Netz laden \n",
    "model.load_weights('my_model_aug.h5')\n",
    "\n",
    "# Musterlösung laden \n",
    "#model.load_weights('solution_model_aug.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 9: Evaluation des neuen Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 9.1: \n",
    "\n",
    "Testen Sie die Performance des neuen Modells, welches auf den originalen und den augmentierten Bildern trainiert wurde,\n",
    "auf den Testdaten. Wie schneidet das neue Modell gegenüber dem alten Modell ab, welches nur auf den originalen Bildern trainiert wurde? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation der Lokalisierung auf den Testdaten \n",
    "threshold = 0.5 # Schwellwert IoU, ab dem Bounding Box als korrekt vorhergesagt betrachtet wird \n",
    "\n",
    "box_true = bboxes_test\n",
    "box_pred = model.predict(x_test)[0]\n",
    "\n",
    "eval_bbox_prediction(box_true,box_pred,threshold)\n",
    "\n",
    "# Evaluation der Klassifikation\n",
    "eval_class_prediction(class_test, model.predict(x_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_9_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 9.2:\n",
    "\n",
    "Testen Sie nun, wie sich die Performance des neuen Modells verhält, wenn man Rauschen auf die Bilder legt. \n",
    "\n",
    "a) Experimentieren Sie mit der Menge an Rauschen. Wie schneidet das neue Modell im Vergleich mit dem alten Modell ab?\n",
    "\n",
    "b) Bei der Augmentierung der Bilder wurde Rauschen in Form von sogenanntem 'salt and pepper noise' (mode='s&p') zu den Bildern hinzugefügt. Es gibt aber auch andere Arten von Rauschen. Wie gut ist die Performance des neuen Modells, wenn man die Art des Rauschens in 'gaussian' oder 'poisson' ändert? Was sagt dies über die Robustheit des Modells aus?    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_noise = 0.001 # Menge an Rauschen\n",
    "\n",
    "def noisy_image(input_imgs):\n",
    "    noisy_imgs = np.copy(input_imgs)\n",
    "    for i in range(len(input_imgs)):\n",
    "        noisy_imgs[i] = random_noise(noisy_imgs[i], mode='s&p', clip=True, amount=amount_of_noise)\n",
    "        #noisy_imgs[i] = random_noise(noisy_imgs[i], mode='gaussian')\n",
    "        #noisy_imgs[i] = random_noise(noisy_imgs[i], mode='poisson')    \n",
    "    return noisy_imgs\n",
    "\n",
    "x_test_noisy = noisy_image(x_test)\n",
    "\n",
    "# Plotte Beispielbild mit Rauschen\n",
    "plt.imshow(x_test_noisy[0], origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bbox_prediction(bboxes_test,model.predict(x_test_noisy)[0],threshold=0.5)\n",
    "eval_class_prediction(class_test, model.predict(x_test_noisy)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe a) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_9_2_a.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe b) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_9_2_b.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwendung auf dem realen Datensatz - Objekt- und Lageerkennung für Robotergreifen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden sollen die, anhand des simplen synthetischen Datensatzes kennengelernten, Ansätze und Methoden auf einen realen Datensatz übertragen werden. Ziel ist es, eine Objekt- und Lageerkennung für das Greifen unterschiedlicher, chaotisch bereitgestellter Objekte umzusetzen. Bei den Objekten handelt es sich um unterschiedliche Werkzeuge, die vom Roboter von einem Tisch gegriffen und anschließend an definierter Stelle wieder abgelegt werden sollen.  \n",
    "\n",
    "Eine Einführung in den behandelten Anwendungsfall und die verwendeten Daten wird im Kurselement \"Anwendungsfall Robotergreifen\" gegeben. Sie können gerne noch einmal zu diesem Kurselement zurückkehren, bevor Sie mit der praktischen Übung fortfahren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 10: Exploration des realen Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 10.1: \n",
    "  \n",
    "Machen Sie sich zunächst mit dem realen Datensatz vertraut. Wie viele Bilder beinhaltet der Datensatz? In welcher Form werden Bilder und Labels hier gespeichert? Wie viele verschiedene Klassen beinhaltet der Datensatz? Betrachten Sie dazu auch beispielhaft einige der realen Bilder.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angleichen des realen Datensatzes an die bekannte Datenstruktur \n",
    "%run data_transfer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten einiger Beispielbilder\n",
    "plot_example_imgs(imgs,bboxes,classes)\n",
    "\n",
    "# Datenstruktur\n",
    "print('imgs:', imgs.shape)\n",
    "print('bboxes:', bboxes.shape)\n",
    "print('classes:', classes.shape)\n",
    "\n",
    "# Klassen\n",
    "print('Klassen:',class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_10_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 11: Datenvorverarbeitung für den realen Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 11.1: \n",
    "\n",
    "Welche Vorverarbeitungsschritte wurden für den synthetischen Datensatz durchgeführt? Führen Sie die gleichen Vorverarbeitungsschritt für den realen Datensatz durch. Ergänzen Sie dazu den gegebenen Code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorverarbeitungsschritt 1\n",
    "imgs_scaled = \n",
    "\n",
    "# Vorverarbeitungsschritt 2\n",
    "bboxes = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_11_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 12: Sampling für den realen Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 12.1: \n",
    "\n",
    "Als Nächstes muss der reale Datensatz in Trainingsdaten und Testdaten aufgeteilt werden. Dabei sollen 80 % der Daten als Trainingsdaten und 20 % der Daten als Testdaten verwendet werden. \n",
    "\n",
    "a) Ergänzen Sie den fehlenden Code.\n",
    "\n",
    "b) Warum ist es hier wichtig, die Daten vor der Aufteilung zu durchmischen? Werfen Sie dazu einen Blick in den Unterordner images im Ordner simple-tools-images-main. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilung der Daten in Trainings- und Testdaten \n",
    "\n",
    "# Durchmischen der Daten vor der Aufteilung  \n",
    "imgs_scaled = np.array(imgs_scaled)\n",
    "imgs_scaled, bboxes, classes = shuffle(imgs_scaled, bboxes, classes)\n",
    "\n",
    "n_train = #Anzahl der Bilder, die zum Trainingsdatensatz gehören sollen\n",
    "\n",
    "# Trainingsdaten\n",
    "x_train = # Die ersten n_train Bilder gehören zum Trainingsdatensatz\n",
    "bboxes_train = \n",
    "class_train = \n",
    "\n",
    "# Testdaten \n",
    "x_test = # Die restlichen Bilder gehören zum Testdatensatz \n",
    "bboxes_test =\n",
    "class_test = \n",
    "\n",
    "print(\"Anzahl Bilder Trainingsdatensatz: \", len(x_train))\n",
    "print(\"Anzahl Bilder Testdatensatz: \", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe a) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_12_1_a.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe b) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_12_1_b.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 13: Augmentierung des realen Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 13.1:\n",
    "\n",
    "Führen Sie den folgenden Code aus, um die Trainingsdaten mit augmentierten Bildern anzureichern und betrachten Sie einige Beispielbilder aus dem neuen Trainingsdatensatz.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugung augmentierter Bilddaten \n",
    "aug_imgs, aug_bboxes, aug_classes = create_augmented_imgs(x_train, bboxes_train, class_train)\n",
    "\n",
    "# Erstellung eines neuen Trainingsdatensatzes mit den originalen und den augmentierten Bildern  \n",
    "x_train_aug = np.concatenate((x_train,aug_imgs), axis=0)\n",
    "bboxes_train_aug = np.concatenate((bboxes_train,aug_bboxes), axis=0)\n",
    "class_train_aug = np.concatenate((class_train,aug_classes), axis=0)\n",
    "\n",
    "# Durchmischung der Bilder\n",
    "x_train_aug, bboxes_train_aug, class_train_aug = shuffle(x_train_aug, bboxes_train_aug, class_train_aug)\n",
    "\n",
    "# Plotten einiger Beispielbilder\n",
    "N,h,b,c = aug_imgs.shape\n",
    "size = np.array([b,h,b,h])\n",
    "plot_example_imgs(aug_imgs, aug_bboxes*size, aug_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 14: Umsetzung Objekterkennung für den realen Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 14.1:\n",
    "\n",
    "Im Folgenden soll eine Objekterkennung mit einem Convolutional Neural Network (CNN) für den realen Datensatz umgesetzt werden. Dafür soll das in Aufgabe 5.1 definierte Modell wiederverwendet werden. Der Code aus Aufgabe 5.1 ist im Folgenden gegeben. Vergleichen Sie die Struktur des realen Datensatzes und des synthetischen Datensatzes. Kann das Modell aus Aufgabe 5.1 eins zu eins so verwendet werden? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    # Eingabe\n",
    "    inputs = Input(shape=x_train.shape[1:])\n",
    "    \n",
    "    # CNN\n",
    "    x = Convolution2D(filters=32,kernel_size=(3,3), activation=\"relu\")(inputs)\n",
    "    x = MaxPool2D(pool_size=(3,3))(x)\n",
    "    x = Convolution2D(filters=16,kernel_size=(3,3), activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(3,3))(x)\n",
    "    x = Convolution2D(filters=8,kernel_size=(3,3), activation=\"relu\")(x)\n",
    "    x = MaxPool2D(pool_size=(3,3)) (x)\n",
    "    x = Flatten() (x)\n",
    "\n",
    "    # Lokalisierung (Regressionsproblem)\n",
    "    x_1 = Dense(128, activation=\"relu\")(x)\n",
    "    x_1 = Dropout(0.3)(x_1)\n",
    "    x_1 = Dense(64,  activation=\"relu\")(x_1)\n",
    "    x_1 = Dropout(0.3)(x_1)\n",
    "    output_bb = Dense(4, activation=\"sigmoid\", name='output_bb')(x_1) # Ausgabe Bounding Box\n",
    "\n",
    "    # Klassifizierung (Klassifikationsproblem)\n",
    "    x_2 = Dense(64, activation=\"relu\")(x)\n",
    "    x_2 = Dropout(0.3)(x_2)\n",
    "    x_2 = Dense(32, activation=\"relu\")(x_2)\n",
    "    x_2 = Dropout(0.3)(x_2)\n",
    "    output_class = Dense(3, activation=\"softmax\", name='output_class')(x_2) # Ausgabe Wahrscheinlichkeit Objektklasse\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[output_bb, output_class])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "# Speichern der zufällig initialisierten Gewichte des Modells \n",
    "model.save_weights('real_model_default_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Teilaufgabe a) laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_14_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 14.2: \n",
    "\n",
    "Trainieren Sie das Modell auf den augmentierten Trainingsdaten für den realen Anwendungsfall. \n",
    "\n",
    "Das Training des Modells benötigt ca. 10 Minuten. Falls das Training zu lange dauert, können Sie auch die Musterlösung laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 # Lernrate\n",
    "num_epochs = 40 # Anzahl Epochen\n",
    "batch_size = 64 # Batch size\n",
    "\n",
    "# Gewichtung der Fehler \n",
    "w_1 = 10.0 # Lokalisierung\n",
    "w_2 = 1.0 # Klassifizierung\n",
    "\n",
    "# Laden der zufälligen Startgewichte des Netzes  \n",
    "model.load_weights('real_model_default_weights.h5')\n",
    "\n",
    "opt = Adam(learning_rate=lr)\n",
    "\n",
    "model.compile(loss={'output_bb' : 'mean_squared_error', 'output_class' : 'categorical_crossentropy'}, \n",
    "              loss_weights=[w_1,w_2],\n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "                            filepath=\"my_real_model_aug.h5\",\n",
    "                            monitor='val_loss',\n",
    "                            mode='min',\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=False)\n",
    "\n",
    "history = model.fit(\n",
    "                    x_train_aug,\n",
    "                    (bboxes_train_aug, class_train_aug),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sie können entweder mit dem von Ihnen trainierten Netz weiterarbeiten oder mit der Musterlösung \n",
    "\n",
    "# Von Ihnen trainiertes Netz laden \n",
    "model.load_weights('my_real_model_aug.h5')\n",
    "\n",
    "# Musterlösung laden \n",
    "#model.load_weights('solution_real_model_aug.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schritt 15: Evaluation der Objekterkennung für den realen Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 15.1:\n",
    "\n",
    "Testen Sie die Performance des trainierten Modells auf dem Testdatensatz. Wie gut funktioniert die Lokalisierung und die Klassifikation der Werkzeuge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation der Lokalisierung auf den Testdaten \n",
    "threshold = 0.5 # Schwellwert IoU, ab dem Bounding Box als korrekt vorhergesagt betrachtet wird \n",
    "\n",
    "box_true = bboxes_test\n",
    "box_pred = model.predict(x_test)[0]\n",
    "\n",
    "eval_bbox_prediction(box_true,box_pred,threshold)\n",
    "\n",
    "# Evaluation der Klassifikation auf den Testdaten\n",
    "eval_class_prediction(class_test, model.predict(x_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_15_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufgabe 15.2:\n",
    "\n",
    "Insbesondere bei der Lokalisierung gibt es in Bezug auf die Performance des Modells noch Luft nach oben. Überlegen Sie sich, wie die Performance des Modells möglicherweise verbessert werden könnte.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung\n",
    "Indem Sie die nächste Zeile ausführen, können Sie die Lösung der Aufgabe laden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_15_2.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6hozRl4hm3w3",
    "r9-FqWYcFzQd",
    "0dGQQ_hIFsyh",
    "KAaZ4q9cjqAC",
    "5K97na61X0a1",
    "1A8J0Aplt5pw"
   ],
   "name": "AKIPRO_Obj_Detection.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "9d2aed3bef1c14b2993d8e731e7fb309ac4819628b24d7a1972b58c369b8e83d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
