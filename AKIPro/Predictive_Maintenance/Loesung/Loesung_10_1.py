solution = str('Hinweis: Die Lösung bezieht sich auf die Musterlösung.\n \nRelevante Kriterien für die Beurteilung der beiden Anomalieerkennungen sind u.a.:\n Wie früh wird der drohende Ausfall erkannt?\n Wie scharf ist die Trennung zwischen Normalfall und Anomalie?\n Wie viele False-Positives treten auf, d.h. wie häufig werden normale Datenpunkte fälschlicherweise als Anomalie erkannt?\n Wie viele False-Negatives treten auf, d.h. wie häufig werden Anomalien nicht als solche erkannt?\n \nBei der Anoamlieerkennung mit KNN wird der drohende Ausfall zum Zeitpunkt 2004-02-16T04:02:39.000000000 erkannt und bei der Anomalieerkennung mit Autoencoder zum Zeitpunkt 2004-02-16T07:32:39.000000000. Beide Anomalieerkennungen schlagen somit am gleichen Tag Alarm, wobei die Anomalieerkennung mit KNN bereits dreieinhalb Stunden früher vor dem Aufall warnt. Darüber hinaus ist die Trennung zwischen Normal und Anomalie bei der KNN-Variante sehr scharf, während es bei der Autoencoder-Variante einen Bereich gibt, in dem die Erkennung zwischen Normal und Anomalie hin und her springt. Bei beiden Anomalieerkennungen treten eine Handvoll False-Positives auf, wobei sich die beiden Varianten hier kaum unterscheiden. False-Negatives treten bei der Anomalieerkennung mit Autoencoder etwas häufiger auf.\n \nIngesamt lässt sich sagen, dass die Anomalieerkennung mit KNN hier etwas besser funktioniert, als die Anomalieerkennung mit Autoencoder. Dies zeigt, dass auch klassische ML-Verfahren, wie der K-nächste-Nachbarn Algorithmus bei nicht all zu schwierigen Problemen sehr gut funktionieren können. Dass die Anomalieerkennung mit Autoencoder hier schlechter funktioniert, könnte auf eine nicht optimale Wahl der Hyperparameter des neuronalen Netzes zurückzuführen sein oder auf eine nicht optimale Wahl des Schwellwerts.')

print(solution)
