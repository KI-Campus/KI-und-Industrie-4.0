{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462a1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Autoren: Omar De-Mitri, Hang Beom Kim, Martina Köhler, Januray 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70bf6c0",
   "metadata": {},
   "source": [
    "# Übung Sicherheitskritische Anwendungen\n",
    "\n",
    "## Einleitung\n",
    "\n",
    "In diesem Modul soll mithilfe eines neuronalen Netzes, welches auf Bildern trainiert wurde, überprüft werden, ob die Anwendung sicher ist oder nicht. Dafür wurde eine Kamera über dem Arbeitsplatz angebracht. Der Datensatz besteht aus Bildern von dieser Kamera. Wenn keine Hand auf den Bildern zu sehen ist, dann ist der Arbeitsplatz sicher. Sobald eine Hand zu sehen ist, soll das neuronale Netz den Arbeitsplatz als unsicher kategorisieren. \n",
    "\n",
    "Diese Art von Klassifizierung kann man sich bei der Ein- und Abschaltung eines Greifroboters vorstellen, der sich, sobald eine menschliche Hand in die Nähe kommt, sofort ausschalten muss. \n",
    "\n",
    "## Schritt 1: Herunterladen der Daten\n",
    "\n",
    "### Aufgabe 1.1\n",
    "\n",
    "Als erstes muss der Datensatz heruntergeladen werden. \n",
    "Innerhalb dieses Ordners befindet sich die Datei \"AKIPRO_safety_application_dataset.zip\". Dafür entpacken Sie bitte diesen Ordner \"AKIRPO_safetey_application_dataset\" in dem selben Ordner, in dem auch das Jupyter Notebook `AKIPRO_safety_applications.ipynb` liegt. \n",
    "\n",
    "Die ursprüngliche Ordnerstruktur von \"safe\" und \"unsafe\" muss beibehalten werden, damit das Skript die Bilder korrekt klassifizieren kann. Diese Struktur wird später genutzt, um die Daten korrekt zu kategorisieren.\n",
    "\n",
    "\n",
    "## Schritt 2: Exploration der Daten\n",
    "\n",
    "Relevante Bibliotheken in das Skript reinladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8425c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41211d99",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Zunächst geben wir dem Skript mithilfe von `os.path` die korrekte Ordnerstruktur. Falls Ihr Ordner, der die Daten beinhaltet, doch einen anderen Namen trägt, kann das hier angepasst werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d57967",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_str = \"AKIPRO_safety_application_dataset\"\n",
    "safe_str = \"safe\"\n",
    "unsafe_str = \"unsafe\"\n",
    "\n",
    "# os.path.join verbindet Strings zu Dateipfaden und funktioniert auf allen Betriebssystemem\n",
    "safe_dir = os.path.join(dir_str, safe_str)\n",
    "unsafe_dir = os.path.join(dir_str, unsafe_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb540aa8",
   "metadata": {},
   "source": [
    "### Aufgabe 2.1 \n",
    "\n",
    "Das neuronale Netz wird mit sowohl Bildern, die als sicher kategorisiert wurden, als auch mit Bildern, die als unsicher klassifiziert wurden trainiert. Im Ordner des Datensatzes sind die Bilder kategorisiert, indem man sie in einem der Ordner `safe` oder `unsafe` abgelegt wurden. Zunächst ist es wichtig, erste Einblicke in die Daten zu bekommen, mit denen das neuronale Netz trainiert wird.\n",
    "\n",
    "Dafür schauen Sie sich bitte ein paar Bilder aus beiden Kategorien an. Somit erhalten Sie ein erstes Gefühl für die Art von Daten, die das neuronale Netz als Input bekommt. \n",
    "\n",
    "Welche Größen haben die einzelnen Bildarrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ac2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bild der sicheren Kategorie laden\n",
    "img_path = os.path.join(safe_dir, \"akipro_0000000000.jpg\")\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Bild der sicheren Kategorie anzeigen\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "plt.xticks([]), plt.yticks([])  # Dadurch werden keine Striche an den Achsen angezeigt\n",
    "plt.title(\"sicher\")\n",
    "plt.show()\n",
    "\n",
    "# Bild der unsicheren Kategorie laden\n",
    "\n",
    "# Bild der unsicheren Kategorie anzeigen\n",
    "\n",
    "# Maximal- und Minimalwerte des Bildes\n",
    "print(f\"Maximum der Bildwerte: {np.max(img)}, , Minimum der Bildwerte: {np.min(img)}\")\n",
    "\n",
    "# Größe des Bildes\n",
    "# print(f\"Größe des Bildes: {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06611469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Tipps/Tipp_2_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8944f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_2_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd9df7",
   "metadata": {},
   "source": [
    "## Schritt 3: Datensatz mit Keras erstellen\n",
    "\n",
    "Nun können die Daten mithilfe von Keras in das Skript geladen werden. Dafür werden in den Folgenden Zellen verschiedenen Funktionen erstellt und verwendet. Versuchen Sie die einzelnen Schritte nachzuvollziehen und ergänzen Sie den Code an den angegebenen Stellen. Die nachfolgende Zelle importiert die notwendigen Bibliotheken und Funktionen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deab4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# ML libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d5711e",
   "metadata": {},
   "source": [
    "### Aufgabe 3.1\n",
    "\n",
    "In diesem Abschnitt werden die .csv Dateien für den Trainings- und Testdatensatz geladen. Bitte ergänzen Sie den Code an den zwei angegebenen Stellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb89a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_file(dir):\n",
    "    # Zunächst werden die Pfade definiert. Bitte ergänzen Sie die Zeile für das Test.csv\n",
    "    csv_path_train = os.path.join(dir, \"Training.csv\")\n",
    "    csv_path_test = os.path.join(dir, \"Test.csv\")\n",
    "\n",
    "    # Jetzt werden die Dateien erstellt und die Spaltennamen geschrieben\n",
    "    # Training\n",
    "    with open(csv_path_train, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"ImageId\", \"PredictionString\"])\n",
    "    # Test\n",
    "    # Platz für Ihren Code\n",
    "\n",
    "    # Anzeigen der verschiedenen Klassen -> Es werden nur die Ordner verwendet\n",
    "    list_of_classes = [element for element in os.listdir(dir) if not os.path.isfile(os.path.join(dir, element))]\n",
    "    print(f\"Liste aller Klassen: {str(list_of_classes)}\")\n",
    "\n",
    "    # Iteriere über alle Klassen\n",
    "    for current_class in list_of_classes:\n",
    "        class_dir = os.path.join(dir, current_class)\n",
    "        # Liste aller .jpg Dateien im Ordner der aktuellen Klasse\n",
    "        #for file in os.listdir(class_dir)\n",
    "        list_of_files = [file for file in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, file)) and file.endswith(\".jpg\")]\n",
    "        \n",
    "        # Dateien zufällig mischen\n",
    "        random.seed(0)\n",
    "        random.shuffle(list_of_files)\n",
    "\n",
    "        # Dateien in Trainings- und Testdaten splitten\n",
    "        train_end = int(len(list_of_files) * 0.75)\n",
    "        train_files = list_of_files[:train_end]\n",
    "        test_files = list_of_files[train_end:]\n",
    "\n",
    "        # Hier werden die Dateiname in die .csv Dateien geschrieben\n",
    "        # Training\n",
    "        with open(csv_path_train, 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for file in train_files:\n",
    "                writer.writerow([file, current_class])\n",
    "\n",
    "        # Test\n",
    "        # Platz für Ihren Code\n",
    "\n",
    "\n",
    "# Verzeichnis, in dem der Datensatz liegt\n",
    "input_dir = 'AKIPRO_safety_application_dataset'\n",
    "\n",
    "# Erstellen der .csv Dateien\n",
    "create_csv_file(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8100259",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_3_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e3283",
   "metadata": {},
   "source": [
    "### Aufgabe 3.2 \n",
    "Im folgenden Codeabschnitt soll eine Funktion erstellt werden, mit der die Dateien gemäß der .csv Dateiein geladen werden können.\n",
    "Beantworten Sie die Fragen im Code. \n",
    "Die [Pandas API Reference](https://pandas.pydata.org/pandas-docs/stable/reference/index.html) kann Ihnen dabei helfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, csv_file):\n",
    "    # Diese Zeile lädt die eben erstelle .csv Datei in ein Pandas DataFrame\n",
    "    csv_df = pd.read_csv(os.path.join(path, csv_file), dtype={'ImageId':str,'PredictionString':str})\n",
    "    # Gibt den \"Kopf\" des DataFrames aus\n",
    "    print(csv_df.head())\n",
    "    data = []\n",
    "    csv_df['ImageId'] = csv_df['ImageId']\n",
    "    \n",
    "    for idx, data_row in csv_df.iterrows():\n",
    "        image_id = data_row[\"ImageId\"]\n",
    "        label = data_row[\"PredictionString\"]\n",
    "        data_tuple = (os.path.join(path, label, image_id), label)\n",
    "        data.append(list(data_tuple))\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['imagename', 'label'])\n",
    "\n",
    "    # Diese Zeile mischt die Zeilen des DataFrames. Warum benötigen Sie diese Zeile? Was gibt der Parameter frac an, warum ist er hier 1?\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Laden der Datensätze\n",
    "df_train = load_dataset(input_dir,'Training.csv')\n",
    "df_test = load_dataset(input_dir,'Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_3_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c73c5",
   "metadata": {},
   "source": [
    "### Aufgabe 3.3 \n",
    "Preprocessing. Versuchen Sie die nachfolgende Funktion nachzuvollziehen. Warum wird dieser Schritt benötigt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a7f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    image = np.array(image)\n",
    "    image /= 255\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c22f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_3_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29436e",
   "metadata": {},
   "source": [
    "### Aufgabe 3.4\n",
    "Im Folgenden Abschnitt werden sogenannte Generatoren für die Datensätze erstellt. Diese Schritte sind etwas komplexer. Daher beschränkt sich Ihre Aufgabe darauf den folgenden Code möglichst gut zu verstehen. Lesen Sie sich dazu die [Dokumentation des ImageDataGenerators](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3cfd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breite und Höhe der Bilder\n",
    "width, height = 720, 540\n",
    "\n",
    "def create_generator(dataset, df):\n",
    "    # Hinweis: Nur die Trainingsdaten werden augmentiert. Rotation, horizontale/vertikale Spiegelung, etc.\n",
    "    trainDataGenerator=ImageDataGenerator(\n",
    "            rescale = None,\n",
    "            rotation_range = 40,\n",
    "            horizontal_flip = True,\n",
    "            vertical_flip = True,\n",
    "            validation_split=0.25,\n",
    "            brightness_range=[0.3,1.0],\n",
    "            preprocessing_function=preprocessing\n",
    "        )\n",
    "        \n",
    "    testDataGenerator=ImageDataGenerator(rescale=None, preprocessing_function=preprocessing)\n",
    "\n",
    "    if dataset == 'Training':\n",
    "        # Training\n",
    "        train_generator=trainDataGenerator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=None,\n",
    "            x_col=\"imagename\",\n",
    "            y_col=\"label\",\n",
    "            subset=\"training\",\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            seed=42,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=(width, height))\n",
    "\n",
    "        # Validierung\n",
    "        valid_generator=trainDataGenerator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=None,\n",
    "            x_col=\"imagename\",\n",
    "            y_col=\"label\",\n",
    "            subset=\"validation\",\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            seed=42,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=(width, height))\n",
    "\n",
    "        return train_generator, valid_generator\n",
    "    \n",
    "    elif dataset == 'Test':\n",
    "        test_generator=testDataGenerator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=None,\n",
    "            x_col=\"imagename\",\n",
    "            y_col=\"label\",\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            seed=42,\n",
    "            class_mode=\"categorical\",\n",
    "            target_size=(width, height))\n",
    "        \n",
    "        return test_generator\n",
    "    \n",
    "    else:\n",
    "        AttributeError(\"Please choose either Training or Test as dataset\")\n",
    "\n",
    "\n",
    "# Erstellen der Generatoren\n",
    "train_generator, valid_generator = create_generator('Training', df_train)\n",
    "test_generator = create_generator('Test', df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82822c3d",
   "metadata": {},
   "source": [
    "### Aufgabe 3.5\n",
    "Wie sind die Labels der Daten im Code repräsentiert?\n",
    "Schauen Sie sich das Pandas DataFrame `df_train` und den `train_generator` genauer an.\n",
    "Welche Klasse wird mit 0 und welche Klasse wird mit 1 repräsentiert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "761b1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Ihren Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaed081",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Tipps/Tipp_3_5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_3_5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb1701",
   "metadata": {},
   "source": [
    "### Aufgabe 3.6\n",
    "Wie viele Bilder gibt es in den jeweiligen Kategorien? (Trainingsdatensatz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_count, unsafe_count = 0, 0\n",
    "\n",
    "for idx, data_row in df_train.iterrows():\n",
    "    # label = ...\n",
    "    # Ergänzen Sie hier Ihren Code\n",
    "\n",
    "print(f\"Die sichere Klasse beinhaltet {safe_count} Bilder.\")\n",
    "print(f\"Die unsichere Klasse beinhaltet {unsafe_count} Bilder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_3_6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897c2dc",
   "metadata": {},
   "source": [
    "### Aufgabe 3.7 \n",
    "Interpretieren Sie das Ergebnis aus Aufgabe 3.6. Ist dieser Zustand wünschenswert? Was wären mögliche Lösungsmöglichkeiten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f98a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_3_7.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1281173",
   "metadata": {},
   "source": [
    "## Schritt 4: Modeldefinition & Training\n",
    "\n",
    "Im nächsten Schritt wird das Modell definiert. Versuchen Sie den Code so gut wie möglich zu verstehen. Die [TensorFlow Reference API](https://www.tensorflow.org/api_docs/python/tf) kann Ihnen dabei helfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5474d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create untrained keras model:\n",
    "def init_model():\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    # Eingang des neuronalen Netzes (Dimension der Bilder)\n",
    "    model.add(tf.keras.Input(shape=(width, height, 3)))\n",
    "    # Definition der Hidden Layers\n",
    "    model.add(tf.keras.layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 4, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(3))   \n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, strides=2, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(32))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "    # Dieses Layer projeziert den mehrdimensionalen Tensor auf eine Dimension\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    # Ausgangsschicht\n",
    "    model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
    "    # Definition der Loss Funktion, des Optimierers, der Learning Rate und der Evaluationsmetrik (hier Klassifikationsgenauigkeit)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00001), metrics=[\"acc\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "def training_phase(model, train_generator):\n",
    "    # Definition und ggf. Erstellen des Ordners, in dem das Modell gespeichert werden soll\n",
    "    model_path = 'saved_models'\n",
    "    model_name = 'lr0-00001_model_akipro_security_training'\n",
    "    checkpoint_name = os.path.join(model_path, model_name + \".ckpt\")\n",
    "    if not os.path.isdir(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # Definition callbacks. Diese Funktionen werden zyklisch von der model.fit() Funktion aufgerufen\n",
    "    # EarlyStopping verhindert Overfitting\n",
    "    # ModelCheckpoint speichert die aktuellen Parameter des Modells in sogenannten Checkpoints\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', mode='min', patience=4), \n",
    "                 ModelCheckpoint(checkpoint_name,  verbose=0, save_weights_only=True, save_freq=1)]\n",
    "\n",
    "    step_size_train=train_generator.n//train_generator.batch_size\n",
    "    step_size_valid=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "    print('start training')\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=step_size_train,\n",
    "        epochs=50,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=6,\n",
    "        verbose=1)\n",
    "\n",
    "    # Trainingshistorie speichern\n",
    "    with open(checkpoint_name + '_lr0-00001_history.txt', 'w') as f:\n",
    "        f.write(str(history.history))\n",
    "        f.close()\n",
    "    \n",
    "    # Model speichern\n",
    "    model_path = os.path.join(model_path, 'lr0-00001_model_akipro_security_training')\n",
    "    model.save(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c6de6",
   "metadata": {},
   "source": [
    "### Aufgabe 4.1 \n",
    "\n",
    "Wie viele Schichten hat das neuronale Netz? Um welche Art von neuronalem Netz handelt es sich? Wie viele trainierbare Parameter hat das Netz?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c900cc",
   "metadata": {},
   "source": [
    "Platz für Notizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6fe1e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Ihren Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Tipps/Tipp_4_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_4_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fca36c",
   "metadata": {},
   "source": [
    "## Trainieren\n",
    "\n",
    "Das Modell ist bereit trainiert zu werden. Bevor Sie den Code ausführen, beantworten Sie bitte folgende Fragen:\n",
    "\n",
    "### Aufgabe 4.2\n",
    "Welche Funktion müssen Sie aufrufen, damit dieses Modell nachtrainiert wird? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed19802",
   "metadata": {},
   "source": [
    "Platz für Notizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ac066",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_4_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e989c4bf",
   "metadata": {},
   "source": [
    "### Aufgabe 4.3\n",
    "\n",
    "An welcher Stelle kann die Anzahl der Epochen für das Training geändert werden? Passen Sie diese Hyperparameter an, wenn das Training sehr langsam auf Ihrem Rechner sein sollte. Um das Training zu beschleunigen, können Sie auch `tensorflow-gpu` installieren, wie in Loesung/Loesung_4_2.py bereits erläutert wurde. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f9dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_4_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d0554",
   "metadata": {},
   "source": [
    " Hier können Sie sich entscheiden, ob Sie das vortrainierte Netz nehmen und damit die Übung beenden, oder ob Sie ein Training starten. \n",
    "\n",
    " Die direkt folgende Zelle trainiert ein neues Modell. Die Zelle darunter verwendet das bereits vortrainierte Netz. Probieren Sie ruhig aus, wie sich das Training 2-5 Epochen verhält, auch wenn Sie später das vortrainierte Netz verwenden sollten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a7c02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# trainiere \n",
    "model = init_model()\n",
    "\n",
    "model = training_phase(model, train_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f08f3",
   "metadata": {},
   "source": [
    "### Verwenden des vortrainierten Netzes\n",
    "Falls Sie nicht selbst trainieren möchten oder können, können Sie hier auch das vortrainierte Netz laden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "242cac1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = init_model()\n",
    "model_dir = \"saved_models\"\n",
    "model_name = os.path.join(model_dir, \"lr-0-0001_akipro.security.model\")\n",
    "model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f868194",
   "metadata": {},
   "source": [
    "## Schritt 5: Loss- & Accuracy-Kurve untersuchen\n",
    "### Aufgabe 5.1\n",
    "\n",
    "Versuchen Sie nun die Kurve der Lossfunktion und die Kurve der Accuracywerte mithilfe der `matplotlib`-Bibliothek zu erstellen. Die [Dokumentation der plot-Funktion](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) kann Ihnen dabei helfen. Achten Sie darauf, dass die Plots korrekte Achsenbeschriftungen und eine Legende haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "history_path = os.path.join(model_dir, \"model_akipro_security.ckpt_lr-0-0001_history.txt\")\n",
    "with open(history_path, 'r') as file:\n",
    "    history = file.readlines()\n",
    "\n",
    "# Kovertieren als Dictionary\n",
    "hist_dict = ast.literal_eval(history[0])\n",
    "\n",
    "# Laden in separate Listen\n",
    "train_loss = hist_dict[\"loss\"]\n",
    "val_loss = hist_dict[\"val_loss\"]\n",
    "# Ergänzen Sie hier die zwei Zeilen für die Accuracy\n",
    "\n",
    "# Loss-Kurve\n",
    "plt.plot(train_loss, label=\"train_loss\")\n",
    "# Platz für Ihren Code\n",
    "plt.show()\n",
    "\n",
    "# Accuracy-Kurve\n",
    "# Platz für Ihren Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b928c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Tipps/Tipp_5_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_5_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5962cfc",
   "metadata": {},
   "source": [
    "### Aufgabe 5.2\n",
    "\n",
    "Wie ist die Kurve der Lossfunktion und die Accuracywerte zu bewerten? Was bedeuten sie? Was wären Accuracywerte überhalb der Zufallsschwelle bei einer binären Klasse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77965d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_5_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b7a25",
   "metadata": {},
   "source": [
    "## Schritt 6: Evaluation und Visualisierung\n",
    "\n",
    "### Aufgabe 6.1 \n",
    "\n",
    "Welche Funktion kann in Keras verwendet werden, um das trainierte Modell zu evaluieren?\n",
    "Schauen Sie sich dazu die [Dokumentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model) an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339f97b",
   "metadata": {},
   "source": [
    "Platz für Notizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ccd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_6_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c4144",
   "metadata": {},
   "source": [
    "Die folgende Zelle enthält eine Helferfunktion, die Ihnen das Preprocessing eines einzelnen Bildes abnimmt. Das Bild wird zu einem Array konvertiert. Anschließend wird eine Dimension hinzugefügt, damit das Bild die dimension `(1, width, height, 3)` statt `(width, height, 3)` hat.\n",
    "Das ist notwendig, da das neuronale Netz am Einagng normalerweise `N` Bilder erwartet also einen Tensor der Dimension `(N, width, height, 3)`. Bei einem einzigen Bild gilt `N=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5747ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "# helper functions:\n",
    "def prepare_image(path):\n",
    "    img = image.load_img(path, target_size=(width, height))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array_expanded_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a76f2",
   "metadata": {},
   "source": [
    "### Aufgabe 6.2 \n",
    "\n",
    "Geben Sie ein paar Bilder mit Ihren vorhergesagten Labels aus. Zu welchem Datensatz gehören die unten abgegebene 4 Beispiele? Schauen Sie sich dazu noch einmal die .csv Dateien an. Warum ist diese Wahl sinnvoll? Ergänzen Sie den folgenden Code an den angegebnen Stellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Beispiel-Bilder\n",
    "img_unsafe = os.path.join(\"AKIPRO_safety_application_dataset\", \"unsafe\", \"akipro_0000002634.jpg\")\n",
    "img_safe_background = os.path.join(\"AKIPRO_safety_application_dataset\", \"safe\", \"akipro_0000000524.jpg\")\n",
    "img_safe_coin_hand = os.path.join(\"AKIPRO_safety_application_dataset\", \"safe\", \"akipro_0000001156.jpg\")\n",
    "img_safe_coin = os.path.join(\"AKIPRO_safety_application_dataset\", \"safe\", \"akipro_0000001666.jpg\")\n",
    "\n",
    "image_paths = [img_unsafe, img_safe_background, img_safe_coin_hand, img_safe_coin]\n",
    "# Befüllen Sie die Liste mit 0 und 1 gemäß den Beispielbildern\n",
    "# true_labels = []  # safe -> 0, unsafe -> 1\n",
    "\n",
    "for (img_path, true_label) in zip(image_paths, true_labels):\n",
    "    # Ergänzen Sie die folgenden zwei Zeilen\n",
    "    # img_processed = ...\n",
    "    # model_prediction = ... \n",
    "    predicted_label = np.argmax(model_prediction, axis=1)[0]\n",
    "    certainty = model_prediction[0][predicted_label]\n",
    "\n",
    "    display(Image(filename=img_path, width=200))\n",
    "    print(f\"Vorhersage: {predicted_label}, Genauigkeit: {certainty:.6f}, Korrekte Klasse: {true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Tipps/Tipp_6_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_6_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f3e50",
   "metadata": {},
   "source": [
    "Was ist hier schief gelaufen? Warum werden die Bilder teilweise mit dem Testdatensatz falsch vorhergesagt? \n",
    "\n",
    "Wie bereits festgestellt, gibt es vier Gruppen von Bildern. Eine Gruppe von Bildern wurde vom Netz falsch vorhergesagt, denn sobald Hände zu sehen sind, soll das neuronale Netz das Bild als `unsafe` kategorisieren. In unserem Trainingsdatensatz haben wir absichtlich die Bilder, auf denen Hände und die TÜV-Plakette zu sehen sind, als sicher kategorisiert. \n",
    "Dies soll eine Warnung sein, wie einfach es ist, Fehler in selbst erzeugten Datensätzen zu übersehen. Insbesondere für sicherheitskritische Anwendungen ist es wichtig, solche Fehler durch eine geeignete Visualiserung zu erkennen und zu verstehen.\n",
    "\n",
    "Eine andere Möglichkeit ist, dass das neuronale Netz nur die TÜV-Plakette beachtet und lernt, dass das Bild sicher ist, sobald die Plakette zu sehen ist. Die Hände würden in diesem Fall ignoriert werden.\n",
    "\n",
    "Um zu erkennen, worauf das neuronale Netz achtet, schauen wir uns nun die Heat Maps, oder auch Attention Maps, von unterschiedlichen Bildern an. Gehen Sie dafür bitte nochmal zurück zu den Videos und schauen Sie sich das nächste Video in diesem Modul an. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed62a6bc",
   "metadata": {},
   "source": [
    "## Schritt 7: Heatmaps erstellen\n",
    "Versuchen Sie den nachfolgenden Code nachzuvollziehen. Das zugehörige [Paper](https://arxiv.org/abs/1910.01279) kann Ihnen dabei zusätzlich helfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ec5826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "import cv2\n",
    "\n",
    "def score_CAM(layer_name, preproc_img, model, predicted_label=None):\n",
    "    # Vorhersage laden, sofern nicht vorhanden\n",
    "    if predicted_label is None:\n",
    "        predicted_label = np.argmax(model.predict(preproc_img), axis=1)[0]\n",
    "\n",
    "    ### Schritt 1: Generieren der intermediate Outputs\n",
    "    # Erstellen eines Sub-Modells vom ersten Layer bis zum letzen Conv-Layer\n",
    "    last_conv_layer = model.get_layer(layer_name)\n",
    "    activation_model = Model(inputs=model.input, outputs=last_conv_layer.output)\n",
    "    \n",
    "    # Generieren der Activations\n",
    "    activations = activation_model.predict(preproc_img)\n",
    "    # Verschieben der letzten Dimension auf die erste Dimension\n",
    "    activations = np.transpose(np.squeeze(activations), (2, 0, 1))\n",
    "\n",
    "    eps = 1e-6\n",
    "\n",
    "    score_saliency_map = np.zeros((width, height), dtype='float32')\n",
    "    for activation in activations:\n",
    "        ### Schritt 2: Upsampling\n",
    "        # Durch die Pooling Layer sind die Outputs kleiner als das ursprüngliche Bild. Daher ist Upsampling notwendig\n",
    "        saliency_map = cv2.resize(activation, (height, width), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        ### Schritt 3: Normalisierung\n",
    "        # Normalisierung der Attention maps auf den Bereich [0, 1]\n",
    "        min_map, max_map = np.min(saliency_map), np.max(saliency_map)\n",
    "        norm_quotient = np.full(shape=(width, height), fill_value=max_map - min_map)\n",
    "        # eps verhindert eine Division durch 0\n",
    "        norm_saliency_map = np.divide(saliency_map - min_map, norm_quotient + eps)\n",
    "\n",
    "        ### Schritt 4: Maskierung\n",
    "        # Maskierung des Originalbildes\n",
    "        mask = np.repeat(np.expand_dims(norm_saliency_map, axis=-1), repeats=3, axis=-1)\n",
    "        masked_img = mask * np.squeeze(preproc_img, axis=0)\n",
    "\n",
    "        ### Schritt 5: Gewichtung der saliency maps\n",
    "        score = model.predict(np.expand_dims(masked_img, axis=0))[0][predicted_label]\n",
    "        score_saliency_map += score * saliency_map\n",
    "\n",
    "    ### Schritt 6: Normalisierung\n",
    "    score_saliency_map = np.maximum(0, score_saliency_map)  # RELU\n",
    "    score_saliency_map_min, score_saliency_map_max = np.min(score_saliency_map), np.max(score_saliency_map)\n",
    "    score_saliency_map = np.divide(score_saliency_map - score_saliency_map_min, score_saliency_map_max- score_saliency_map_min)\n",
    "\n",
    "    return score_saliency_map\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff10cf",
   "metadata": {},
   "source": [
    "### Aufgabe 7.1\n",
    "Nun können Sie die reingeladenen Bilder von oben wieder verwenden, um herauszufinden, worauf das Netz achtet, wenn das Bild ihm präsentiert wird. \n",
    "\n",
    "Mit welcher Funktion werden die Heat Maps/Attention Maps generiert? Welchen Input hat diese Funktion? Und was ist ihr Output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden Sie die Bilder aus der vorherigen Aufgabe\n",
    "# attention_map_safe_background = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f407cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_7_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b26f6",
   "metadata": {},
   "source": [
    "### Aufgabe 7.2 Visualiserung\n",
    "Ergänzen Sie den Code am Ende der Zelle um die Heatmaps der 4 Bilder anzuzeigen. Nutzen sie dazu die Funktion `plot_heatmap` und beachten sie das Argument `plot_idx`(startet bei 1 und muss pro Bild \"hochgezählt werden\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf19082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(fig, img, heatmap, model, title, plot_idx, rows=2, cols=2):\n",
    "    logit = model.predict(img)\n",
    "    label = np.argmax(logit, axis=1).item()\n",
    "    x_label = f\"label: {label},  mit Sicherheit: {logit[0][label]:.6f}\"\n",
    "\n",
    "    fig.add_subplot(rows, columns, plot_idx)\n",
    "    plt.title(title)\n",
    "    plt.imshow(img[0,:,:, :])\n",
    "    plt.imshow(heatmap, alpha=0.5)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# Bilder laden\n",
    "img_safe_background_processed = prepare_image(img_safe_background)\n",
    "img_safe_coin_hand_processed = prepare_image(img_safe_coin_hand)\n",
    "img_safe_coin_processed = prepare_image(img_safe_coin)\n",
    "img_unsafe_processed = prepare_image(img_unsafe)\n",
    "\n",
    "# Plot Einstellungen\n",
    "rows, columns = 2, 2\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.suptitle('Attention Maps')\n",
    "\n",
    "# Bilder mit Heatmaps plotten\n",
    "# Platz für Ihren Code\n",
    "# \n",
    "# \n",
    "#\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02365be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load Loesung/Loesung_7_2.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741b570",
   "metadata": {},
   "source": [
    "### Aufgabe 7.3\n",
    "\n",
    "Wie lassen sich die obigen Heat Maps interpretieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb286d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Loesung/Loesung_7_3.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python-akipro_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
